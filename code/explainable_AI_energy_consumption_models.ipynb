{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ecd2c44",
   "metadata": {},
   "source": [
    "# Explainable AI (XAI) for Electricity Consumption Forecasting Models\n",
    "\n",
    "In this notebook, we perform residential building electricity consumption forecasting using various ensemble learning models based on decision trees.<br>Since these models are not sensitive to feature scaling, we omit any feature scaling steps.<br>We use two datasets:\n",
    "- **Household dataset**: Appliances Energy Prediction dataset;\n",
    "- **University Residential Complex dataset**: Energy consumption data from a university residential complex.\n",
    "\n",
    "We will:\n",
    "- Load and preprocess the datasets.\n",
    "- Train different ensemble models on each dataset.\n",
    "- Visualize feature importances.\n",
    "- Use SHAP to explain model predictions.\n",
    "- Generate high-quality plots (dpi=1000) for detailed analysis.\n",
    "\n",
    "The figures generated correspond to Figures 4 to 11 in the referenced paper, allowing readers to reproduce and understand the results.\n",
    "\n",
    "---\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "1. [Load and Split the Datasets](#load-and-split-the-datasets)\n",
    "2. [Define Ensemble Models](#define-ensemble-models)\n",
    "3. [Train Models and Generate Feature Importances](#train-models-and-generate-feature-importances)\n",
    "4. [SHAP Analysis](#shap-analysis)\n",
    "5. [Partial Dependence Plots (PDP)](#partial-dependence-plots-pdp)\n",
    "6. [SHAP Decision Plot](#shap-decision-plot)\n",
    "7. [Additional Options and Customizations](#additional-options-and-customizations)\n",
    "8. [Conclusion](#conclusion)\n",
    "9. [Abbreviation Definitions (Table 2)](#abbreviation-definitions-table-2)\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** All plots are saved with a high resolution (dpi=1000) and filenames related to XAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cf7856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install shap\n",
    "!pip install lightgbm\n",
    "!pip install catboost\n",
    "!pip install xgboost\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4963d894",
   "metadata": {},
   "source": [
    "<a name=\"load-and-split-the-datasets\"></a>\n",
    "\n",
    "## 1. Load and Split the Datasets\n",
    "\n",
    "We use the `load_and_split_data` function to load either the 'household' or 'dormitory' dataset.<br>The data are split into training and testing sets based on predefined indices.\n",
    "- household: **Appliances Energy Prediction dataset** \n",
    "- dormitory: **University Residential Complex dataset**\n",
    "\n",
    "### Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55ca656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split_data(dataset_choice):\n",
    "    if dataset_choice == 'household':\n",
    "        data = pd.read_csv('Appliances Energy Prediction.csv')\n",
    "        X_train = data.iloc[:2311, 1:-1]\n",
    "        y_train = data.iloc[:2311, -1]\n",
    "        X_test = data.iloc[2311:, 1:-1]\n",
    "        y_test = data.iloc[2311:, -1]\n",
    "    elif dataset_choice == 'dormitory':\n",
    "        data = pd.read_csv('University Residential Complex.csv')\n",
    "        X_train = data.iloc[:20472, 5:-1]\n",
    "        y_train = data.iloc[:20472, -1]\n",
    "        X_test = data.iloc[20472:, 5:-1]\n",
    "        y_test = data.iloc[20472:, -1]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset choice. Please select 'household' or 'dormitory'.\")\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4b7bcb",
   "metadata": {},
   "source": [
    "### Load the Datasets\n",
    "\n",
    "You can change `dataset_choice` to `'dormitory'` to switch datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375ab393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the dataset\n",
    "dataset_choice = 'dormitory'  # Change to 'household' as needed\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = load_and_split_data(dataset_choice)\n",
    "\n",
    "# Display shapes\n",
    "print(\"Training set shape:\", X_train_raw.shape, y_train_raw.shape)\n",
    "print(\"Test set shape:\", X_test_raw.shape, y_test_raw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd2a4d3",
   "metadata": {},
   "source": [
    "<a name=\"define-ensemble-models\"></a>\n",
    "\n",
    "## 2. Define Ensemble Models\n",
    "\n",
    "We define a dictionary of ensemble models with their respective hyperparameters for both datasets.<br>The models include:\n",
    "- **Random Forest Regressor (RF)**;\n",
    "- **Gradient Boosting Regressor (GBM)**;\n",
    "- **Extreme Gradient Boosting Regressor (XGBoost)**;\n",
    "- **Light Gradient Boosting Machine (LightGBM)**;\n",
    "- **CatBoost Regressor (CatBoost)**.\n",
    "\n",
    "These models are based on decision trees and do not require feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf60a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models for the household dataset\n",
    "models_household = {\n",
    "    'RF': RandomForestRegressor(max_features='sqrt', n_estimators=128, random_state=42, n_jobs=-1),\n",
    "    'GBM': GradientBoostingRegressor(learning_rate=0.05, loss='huber', max_depth=5,\n",
    "                                     n_estimators=500, random_state=42),\n",
    "    'XGBoost': XGBRegressor(booster='gbtree', colsample_bytree=1.0, learning_rate=0.05,\n",
    "                            max_depth=10, n_estimators=1000, subsample=1.0,\n",
    "                            random_state=42, n_jobs=-1),\n",
    "    'LightGBM': LGBMRegressor(boosting_type='gbdt', colsample_bytree=1.0, learning_rate=0.01,\n",
    "                              n_estimators=1000, num_leaves=64, subsample=0.5,\n",
    "                              random_state=42, n_jobs=-1),\n",
    "    'CatBoost': CatBoostRegressor(depth=10, l2_leaf_reg=1, learning_rate=0.03,\n",
    "                                  loss_function='RMSE', random_seed=42, verbose=False)\n",
    "}\n",
    "\n",
    "# Define models for the dormitory dataset\n",
    "models_dormitory = {\n",
    "    'RF': RandomForestRegressor(max_features='sqrt', n_estimators=128, random_state=42, n_jobs=-1),\n",
    "    'GBM': GradientBoostingRegressor(learning_rate=0.05, loss='huber', max_depth=5,\n",
    "                                     n_estimators=500, random_state=42),\n",
    "    'XGBoost': XGBRegressor(booster='gbtree', colsample_bytree=1.0, learning_rate=0.05,\n",
    "                            max_depth=10, n_estimators=1000, subsample=1.0,\n",
    "                            random_state=42, n_jobs=-1),\n",
    "    'LightGBM': LGBMRegressor(boosting_type='gbdt', colsample_bytree=1.0, learning_rate=0.01,\n",
    "                              n_estimators=1000, num_leaves=64, subsample=0.5,\n",
    "                              random_state=42, n_jobs=-1),\n",
    "    'CatBoost': CatBoostRegressor(depth=10, l2_leaf_reg=1, learning_rate=0.1,\n",
    "                                  loss_function='RMSE', random_seed=42, verbose=False)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243c320e",
   "metadata": {},
   "source": [
    "<a name=\"train-models-and-generate-feature-importances\"></a>\n",
    "\n",
    "## 3. Train Models and Generate Feature Importances\n",
    "\n",
    "We train each model on the selected dataset and compute the feature importances.<br>We then plot the feature importances using bar plots.\n",
    "\n",
    "### Training and Feature Importance Plotting\n",
    "\n",
    "You can adjust the `dataset_choice` variable earlier to switch between datasets.\n",
    "\n",
    "**Note:** The plots are saved with a high resolution (dpi=1000) for detailed analysis.\n",
    "\n",
    "---\n",
    "\n",
    "**Fig 4. Influence of input variables in the GBM model on the University Residential Complex dataset:**\n",
    "\n",
    "- **(a) Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34a3207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the appropriate model dictionary based on the dataset\n",
    "if dataset_choice == 'household':\n",
    "    models = models_household\n",
    "    X_train_data = X_train\n",
    "    y_train_data = y_train\n",
    "    X_test_data = X_test\n",
    "    y_test_data = y_test\n",
    "    dataset_label = 'Household'\n",
    "else:\n",
    "    models = models_dormitory\n",
    "    X_train_data = X_train\n",
    "    y_train_data = y_train\n",
    "    X_test_data = X_test\n",
    "    y_test_data = y_test\n",
    "    dataset_label = 'University Residential Complex'\n",
    "\n",
    "# Dictionary to store trained models\n",
    "trained_models = {}\n",
    "feature_importances = {}  # To store feature importances for each model\n",
    "\n",
    "# Iterate over each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining {model_name} on {dataset_label} data...\")\n",
    "    model.fit(X_train_data, y_train_data)\n",
    "    trained_models[model_name] = model\n",
    "\n",
    "    # Compute feature importances\n",
    "    if model_name in ['RF', 'GBM', 'XGBoost', 'LightGBM']:\n",
    "        importances = model.feature_importances_\n",
    "    elif model_name == 'CatBoost':\n",
    "        importances = model.get_feature_importance()\n",
    "    else:\n",
    "        continue  # Skip if model does not support feature importances\n",
    "\n",
    "    # Store feature importances\n",
    "    feature_importances[model_name] = importances\n",
    "\n",
    "    # Create a DataFrame for feature importances\n",
    "    fi_df = pd.DataFrame({\n",
    "        'feature_names': X_train_data.columns,\n",
    "        'feature_importance': importances\n",
    "    })\n",
    "\n",
    "    # Sort the DataFrame by feature importance\n",
    "    fi_df = fi_df.sort_values(by='feature_importance', ascending=False)\n",
    "\n",
    "    # Plot feature importances\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    sns.barplot(x='feature_importance', y='feature_names', data=fi_df,\n",
    "                palette=sns.color_palette(\"husl\", len(fi_df)))\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'Fig4a_XAI_Feature_Importance_{model_name}_{dataset_label}.pdf', dpi=1000)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a483dca4",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- The above code trains each model and plots the feature importance.\n",
    "- For **Fig 4(a)**, we focus on the GBM model on the University Residential Complex dataset.\n",
    "- Ensure that `dataset_choice` is set to `'dormitory'` to reproduce **Fig 4(a)**.\n",
    "\n",
    "---\n",
    "\n",
    "**Fig 8. Influence of input variables in the CatBoost model on the Appliances Energy Prediction dataset:**\n",
    "\n",
    "- **(a) Feature importance**\n",
    "\n",
    "To reproduce **Fig 8(a)**, set `dataset_choice` to `'household'` and focus on the CatBoost model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4fcabb",
   "metadata": {},
   "source": [
    "<a name=\"shap-analysis\"></a>\n",
    "\n",
    "## 4. SHAP Analysis\n",
    "\n",
    "We use SHAP to explain the predictions of each model.<br>SHAP values represent the contribution of each feature to the prediction made by the model.<br>We generate SHAP summary plots for each model.\n",
    "\n",
    "### SHAP Summary Plots\n",
    "\n",
    "**Note:** SHAP plots are saved with a high resolution (dpi=1000) and filenames related to XAI.\n",
    "\n",
    "---\n",
    "\n",
    "**Fig 4.**\n",
    "\n",
    "- **(b) SHAP summary plot for the GBM model on the University Residential Complex dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a241f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP analysis for each model\n",
    "for model_name, model in trained_models.items():\n",
    "    print(f\"\\nPerforming SHAP analysis for {model_name} on {dataset_label} data...\")\n",
    "    # Use TreeExplainer for tree-based models\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_train_data)\n",
    "\n",
    "    # Generate SHAP summary plot\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    shap.summary_plot(shap_values, X_train_data, plot_type=\"dot\", show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'Fig4b_XAI_SHAP_Summary_{model_name}_{dataset_label}.pdf', dpi=1000)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb079fc",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- For **Fig 4(b)**, we use the GBM model on the University Residential Complex dataset.\n",
    "- Ensure that `dataset_choice` is `'dormitory'` and `model_name` is `'GBM'`.\n",
    "\n",
    "---\n",
    "\n",
    "**Fig 5. SHAP summary plots of other ensemble learning models on the University Residential Complex dataset:**\n",
    "\n",
    "- **(a) RF**\n",
    "- **(b) XGBoost**\n",
    "- **(c) LightGBM**\n",
    "- **(d) CatBoost**\n",
    "\n",
    "Repeat the SHAP analysis for the other models (`'RF'`, `'XGBoost'`, `'LightGBM'`, `'CatBoost'`) to generate **Fig 5**, updating filenames accordingly.\n",
    "\n",
    "---\n",
    "\n",
    "**Fig 8.**\n",
    "\n",
    "- **(b) SHAP summary plot for the CatBoost model on the Appliances Energy Prediction dataset.**\n",
    "\n",
    "Set `dataset_choice` to `'household'` and focus on the `'CatBoost'` model to reproduce **Fig 8(b)**.\n",
    "\n",
    "---\n",
    "\n",
    "**Fig 9. SHAP summary plots of other ensemble learning models on the Appliances Energy Prediction dataset:**\n",
    "\n",
    "- **(a) RF**\n",
    "- **(b) GBM**\n",
    "- **(c) XGBoost**\n",
    "- **(d) LightGBM**\n",
    "\n",
    "Repeat the SHAP analysis for these models on the `'household'` dataset to generate **Fig 9**, ensuring filenames are appropriately named with 'XAI'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e65bcf2",
   "metadata": {},
   "source": [
    "<a name=\"partial-dependence-plots-pdp\"></a>\n",
    "\n",
    "## 5. Partial Dependence Plots (PDP)\n",
    "\n",
    "Partial dependence plots show the relationship between the target response and a set of features of interest.<br> They do this by marginalizing over the values of all other features.\n",
    "\n",
    "### Generating PDPs Using scikit-learn and SHAP\n",
    "\n",
    "We compare PDPs generated using scikit-learn's `PartialDependenceDisplay` and SHAP's dependence plots.\n",
    "\n",
    "---\n",
    "\n",
    "**Fig 6. Comparison of PDPs from the GBM model on the University Residential Complex dataset:**\n",
    "\n",
    "- **(a) Analyzing the relationship between holiday status (`Holi`) and average electricity consumption (`Cons_avg`) using scikit-learn**\n",
    "- **(b) Using SHAP analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d684db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for PDPs\n",
    "feature = 'Holi'  # For Fig 6\n",
    "interaction_feature = 'Cons_avg'  # The feature to analyze interaction with\n",
    "\n",
    "# Choose the model (GBM in this case)\n",
    "model_for_pdp = trained_models['GBM']\n",
    "X_data_for_pdp = X_train_data  # Use training data for PDPs\n",
    "\n",
    "# Generate PDP using scikit-learn\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "PartialDependenceDisplay.from_estimator(\n",
    "    model_for_pdp, X_data_for_pdp, features=[feature], kind=\"average\", ax=ax,\n",
    "    line_kw={\"color\": \"red\"}\n",
    ")\n",
    "plt.title(f'PDP using scikit-learn for {feature}')\n",
    "plt.xlabel(feature)\n",
    "plt.ylabel('Partial Dependence')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Fig6a_XAI_PDP_scikit_Holi_Consavg.pdf', dpi=1000)\n",
    "plt.show()\n",
    "\n",
    "# Generate PDP using SHAP\n",
    "plt.figure(figsize=(7, 7))\n",
    "shap.dependence_plot(\n",
    "    ind=feature,\n",
    "    shap_values=shap_values,\n",
    "    features=X_data_for_pdp,\n",
    "    interaction_index=interaction_feature,\n",
    "    show=False\n",
    ")\n",
    "plt.title(f'SHAP Dependence Plot for {feature} and {interaction_feature}')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Fig6b_XAI_PDP_SHAP_Holi_Consavg.pdf', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee833f8",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- **Fig 6(a)**: PDP using scikit-learn for 'Holi' on the University Residential Complex dataset.\n",
    "- **Fig 6(b)**: SHAP dependence plot for 'Holi' interacting with 'Cons_avg'.\n",
    "\n",
    "---\n",
    "\n",
    "**Fig 7. Comparison of PDPs from the GBM model on the University Residential Complex dataset:**\n",
    "\n",
    "- **(a) Analyzing the relationship between temperature-humidity index (`THI`) and `Cons_avg` using scikit-learn**\n",
    "- **(b) Using SHAP analysis**\n",
    "\n",
    "Update the `feature` and `interaction_feature`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f0ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update features for Fig 7\n",
    "feature = 'THI'\n",
    "interaction_feature = 'Cons_avg'\n",
    "\n",
    "# Generate PDP using scikit-learn\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "PartialDependenceDisplay.from_estimator(\n",
    "    model_for_pdp, X_data_for_pdp, features=[feature], kind=\"average\", ax=ax,\n",
    "    line_kw={\"color\": \"red\"}\n",
    ")\n",
    "plt.title(f'PDP using scikit-learn for {feature}')\n",
    "plt.xlabel(feature)\n",
    "plt.ylabel('Partial Dependence')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Fig7a_XAI_PDP_scikit_THI_Consavg.pdf', dpi=1000)\n",
    "plt.show()\n",
    "\n",
    "# Generate PDP using SHAP\n",
    "plt.figure(figsize=(7, 7))\n",
    "shap.dependence_plot(\n",
    "    ind=feature,\n",
    "    shap_values=shap_values,\n",
    "    features=X_data_for_pdp,\n",
    "    interaction_index=interaction_feature,\n",
    "    show=False\n",
    ")\n",
    "plt.title(f'SHAP Dependence Plot for {feature} and {interaction_feature}')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Fig7b_XAI_PDP_SHAP_THI_Consavg.pdf', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0b674c",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- **Fig 7(a)**: PDP using scikit-learn for 'THI' on the University Residential Complex dataset.\n",
    "- **Fig 7(b)**: SHAP dependence plot for 'THI' interacting with 'Consavg'.\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** Ensure that `dataset_choice` is `'dormitory'` and `model_name` is `'GBM'` to reproduce Figures 6 and 7.<br>The filenames include 'XAI' to indicate their relation to explainable AI methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e487f5",
   "metadata": {},
   "source": [
    "<a name=\"shap-decision-plot\"></a>\n",
    "\n",
    "## 6. SHAP Decision Plot\n",
    "\n",
    "SHAP decision plots visualize model predictions by highlighting how the SHAP values of each feature contribute to the final prediction.\n",
    "\n",
    "### Generating SHAP Decision Plot on Test Set\n",
    "\n",
    "We apply the SHAP decision plot to the test set to see how the model makes predictions on unseen data.\n",
    "\n",
    "---\n",
    "\n",
    "**Fig 11. SHAP decision plot for the test set on the Appliances Energy Prediction dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d4b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to Household dataset to reproduce Fig 11\n",
    "dataset_choice = 'household'\n",
    "X_train, X_test, y_train, y_test = load_and_split_data(dataset_choice)\n",
    "\n",
    "# Train the CatBoost model\n",
    "model_catboost_household = models_household['CatBoost']\n",
    "model_catboost_household.fit(X_train, y_train)\n",
    "\n",
    "# Compute SHAP values on test set\n",
    "explainer_test = shap.TreeExplainer(model_catboost_household)\n",
    "shap_values_test = explainer_test.shap_values(X_test)\n",
    "\n",
    "# Generate SHAP decision plot\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "expected_value = explainer_test.expected_value\n",
    "if isinstance(expected_value, np.ndarray):\n",
    "    expected_value = expected_value[0]  # For some models, expected_value is an array\n",
    "shap.decision_plot(\n",
    "    expected_value, shap_values_test[:100], X_test.iloc[:100], feature_order='hclust',\n",
    "    show=False\n",
    ")\n",
    "plt.title('Fig11_XAI_SHAP Decision Plot on Test Set (Appliances Energy Prediction dataset)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Fig11_XAI_SHAP_Decision_Plot_Household.pdf', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508ce71d",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- We apply the SHAP decision plot to the test set of the Appliances Energy Prediction dataset.\n",
    "- The plot shows how each feature contributes to the model's predictions on unseen data.\n",
    "- We limit the plot to the first 100 instances for clarity.\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** Adjust `dataset_choice` and the model accordingly to reproduce **Fig 11**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19ca03c",
   "metadata": {},
   "source": [
    "<a name=\"additional-options-and-customizations\"></a>\n",
    "\n",
    "## 7. Additional Options and Customizations\n",
    "\n",
    "To help readers adjust the code and generate specific figures:\n",
    "- **Adjust Dataset Choice**: Change `dataset_choice` between `'household'` and `'dormitory'` to switch datasets.\n",
    "- **Select Specific Models**: Modify the `models` dictionary or specify `model_name` to focus on specific models.\n",
    "- **Change Features for PDPs**: Update `feature` and `interaction_feature` with desired feature names.\n",
    "- **Customize Plots**: Modify plot sizes (`figsize`), titles, labels, and other parameters in the plotting functions.\n",
    "- **SHAP Options**: Explore different SHAP plots such as `bar`, `violin`, and `beeswarm` plots by changing the `plot_type` parameter.\n",
    "- **Filename Adjustments**: Ensure filenames include 'XAI' to reflect their focus on explainable AI.\n",
    "\n",
    "### Generating Figures 5, 9, and 10\n",
    "\n",
    "**Fig 5** and **Fig 9** correspond to SHAP summary plots of other ensemble learning models.<br>You can generate these by iterating over the models as shown in the SHAP Analysis section, ensuring filenames include 'XAI'.\n",
    "\n",
    "**Fig 10** involves PDPs of the CatBoost model on the Appliances Energy Prediction dataset:\n",
    "\n",
    "---\n",
    "\n",
    "**Fig 10. PDPs of the CatBoost model on the Appliances Energy Prediction dataset:**\n",
    "- **(a) Analyzing the interaction between `Hour_x` and `Hour_y`**\n",
    "- **(b) Analyzing the interaction between `Holi` and `Hour_y`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39018aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "```python\n",
    "# Ensure dataset_choice is 'household'\n",
    "dataset_choice = 'household'\n",
    "X_train, X_test, y_train, y_test = load_and_split_data(dataset_choice)\n",
    "\n",
    "# Use the trained CatBoost model\n",
    "model_catboost_household = models_household['CatBoost']\n",
    "model_catboost_household.fit(X_train, y_train)\n",
    "\n",
    "# Compute SHAP values on training set\n",
    "explainer_catboost = shap.TreeExplainer(model_catboost_household)\n",
    "shap_values_catboost = explainer_catboost.shap_values(X_train)\n",
    "\n",
    "# Generate PDPs for 'Hour_x' and 'Hour_y', 'Holi' and 'Hour_y'\n",
    "features_pairs = [('Hour_x', 'Hour_y'), ('Holi', 'Hour_y')]\n",
    "\n",
    "for features in features_pairs:\n",
    "    # SHAP dependence plot with interaction\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    shap.dependence_plot(\n",
    "        ind=features[0],\n",
    "        shap_values=shap_values_catboost,\n",
    "        features=X_train,\n",
    "        interaction_index=features[1],\n",
    "        show=False\n",
    "    )\n",
    "    plt.title(f'SHAP Dependence Plot for {features[0]} and {features[1]}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'Fig10_XAI_SHAP_Dependence_{features[0]}_{features[1]}_Household.pdf', dpi=1000)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c28893a",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- This code generates SHAP dependence plots analyzing the interaction between specified features.\n",
    "- The plots correspond to **Fig 10(a)** and **Fig 10(b)**.\n",
    "- Filenames include 'XAI' to reflect their focus on explainable AI methods.\n",
    "\n",
    "---\n",
    "<a name=\"conclusion\"></a>\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this notebook, we:\n",
    "- Trained various ensemble models on the selected datasets without feature scaling, as they are based on decision trees.\n",
    "- Analyzed feature importances to understand which features contribute most to the models.\n",
    "- Used SHAP to explain individual predictions and overall feature impact.\n",
    "- Generated high-quality visualizations for detailed analysis, corresponding to Figures 4 to 11.\n",
    "- Provided options and detailed explanations to help readers reproduce and customize the analysis.\n",
    "\n",
    "This comprehensive approach helps in understanding both the performance of the models and the factors influencing their predictions.<br>This insight is crucial for making informed decisions in energy management."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde88ab0",
   "metadata": {},
   "source": [
    "## Table 2: Abbreviation Definitions\n",
    "\n",
    "To understand the abbreviations used in the figures:\n",
    "\n",
    "<a name=\"abbreviation-definitions-table-2\"></a>\n",
    "\n",
    "| Variable | Description                                        | Data Type                           |\n",
    "|:----------|:----------------------------------------------------|:-------------------------------------|\n",
    "| **Timestamp Features**                                        |                                     |\n",
    "| Hour_x    | Hour of the day (sine value)                       | Numeric (Timestamp)                 |\n",
    "| Hour_y    | Hour of the day (cosine value)                     | Numeric (Timestamp)                 |\n",
    "| DOTW_x    | Day of the week (sine value)                       | Numeric (Timestamp)                 |\n",
    "| DOTW_y    | Day of the week (cosine value)                     | Numeric (Timestamp)                 |\n",
    "| Holi     | Weekday: 0; Weekend: 1                             | Binary (Timestamp)                  |\n",
    "| **Weather Conditions**                                        |                                     |\n",
    "| Temp     | Hourly temperature                                 | Numeric (Weather condition)         |\n",
    "| Humi     | Hourly humidity                                    | Numeric (Weather condition)         |\n",
    "| WS       | Hourly wind speed                                  | Numeric (Weather condition)         |\n",
    "| THI      | Hourly temperature-humidity index                  | Numeric (Weather condition)         |\n",
    "| WCT      | Hourly wind chill temperature                      | Numeric (Weather condition)         |\n",
    "| **Historical Electricity Consumption**                        |                                     |\n",
    "| Cons_1    | Power consumption one day before the time point    | Numeric (Historical consumption)    |\n",
    "| Holi_1    | Holiday indicator one day before the time point    | Binary (Historical consumption)     |\n",
    "| Cons_7    | Power consumption one week before the time point   | Numeric (Historical consumption)    |\n",
    "| Holi_7    | Holiday indicator one week before the time point   | Binary (Historical consumption)     |\n",
    "| Cons_avg  | Weekly average power consumption                   | Numeric (Historical consumption)    |\n",
    "\n",
    "**Note:** This table provides definitions for the variables used in the datasets and figures.\n",
    "\n",
    "---\n",
    "\n",
    "**Note to Readers:** Feel free to modify the code to explore different models, datasets, and features.<br>The detailed explanations and code comments are provided to facilitate understanding and customization.\n",
    "\n",
    "---\n",
    "\n",
    "**End of Notebook**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
