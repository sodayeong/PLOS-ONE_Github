{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c051e565",
   "metadata": {},
   "source": [
    "# Advancing Ensemble Learning Models for<br>Residential Building Electricity Consumption Forecasting\n",
    "\n",
    "This notebook implements five ensemble learning models with hyperparameter tuning based on the specified hyperparameters.<br>The optimal hyperparameters for each model will be saved in an `optimal_hyperparameters.txt` file.<br>In addition, evaluation metrics will be calculated to assess model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3610810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install pandas scikit-learn xgboost lightgbm catboost numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dff49b",
   "metadata": {},
   "source": [
    "## Hyperparameters for Ensemble Learning Methods\n",
    "\n",
    "Below are the hyperparameters used for each decision tree-based ensemble learning method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41664b53",
   "metadata": {},
   "source": [
    "| **Methodology**               | **Reference** | **Hyperparameters**                                                                                                                                                                                                                         |\n",
    "|:------------------------------|:--------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Random Forest (RF)**             | [52]          | - Number of Trees: 128<br>- Features per Split: auto, sqrt, log2                                                                                                                                                                            |\n",
    "| **Gradient Boosting Machine (GBM)** | [41]          | - Number of Iterations: 100, 250, 500<br>- Learning Rate: 0.01, 0.05, 0.1<br>- Depth: 5, 10<br>- Loss Type: quantile, Huber                                                                                                                |\n",
    "| **Extreme Gradient Boosting (XGBoost)** | [41]          | - Number of Iterations: 250, 500, 1000<br>- Learning Rate: 0.01, 0.05, 0.1<br>- Depth: 6, 8, 10<br>- Subsampling Rate: 0.5, 0.75, 1.0<br>- Feature Sample by Tree/Level/Node: 0.5, 0.75, 1.0<br>- Booster Type: gbtree, dart                | \n",
    "| **Light Gradient Boosting Machine (LightGBM)** | [41]     | - Number of Iterations: 1000, 1500<br>- Learning Rate: 0.01, 0.05, 0.1<br>- Number of Leaves: 64<br>- Subsample: 0.5<br>- Feature Sample by Tree: 1.0<br>- Booster Type: gbdt, dart                                                      |\n",
    "| **Categorical Boosting (CatBoost)**      | [53]          | - Learning Rate: 0.03, 0.1<br>- Maximum Tree Depth: 4, 6, 10<br>- L2 Regularization Levels: 1, 3, 5, 7, 9                                                                                                                                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794c2484",
   "metadata": {},
   "source": [
    "# Dataset Selection and Splitting\n",
    "\n",
    "This notebook provides a flexible setup for selecting between two datasets: \n",
    "* Household (Appliances Energy Prediction);\n",
    "* Dormitory (University Residential Complex).\n",
    "\n",
    "Based on the selected dataset, we will load, preprocess, and split the data into predefined training and test sets as specified in the paper.<br>The data split follows specific row indices rather than random splitting, ensuring consistency with the methodology.<br>The model development will then proceed with this structured dataset preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c227ea",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n",
    "\n",
    "The necessary libraries for data manipulation, model training, hyperparameter tuning, and evaluation metrics are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6737070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e728c858",
   "metadata": {},
   "source": [
    "## Step 2: Load and Split Dataset Based on User Selection\n",
    "\n",
    "In this section, we define a function `load_and_split_data` that allows us to select either the Household dataset or the Dormitory dataset.<br>Each dataset is split according to specific row ranges as specified in the research paper.\n",
    "\n",
    "- **Household Dataset**:\n",
    "  - Training set: First 2311 rows\n",
    "  - Test set: Rows from 2311 onward\n",
    "\n",
    "- **Dormitory Dataset**:\n",
    "  - Training set: First 20472 rows\n",
    "  - Test set: Rows from 20472 onward\n",
    "\n",
    "The function returns the `X_train`, `X_test`, `y_train`, and `y_test` sets based on the selected dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302f6d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and split dataset based on user's selection and predefined ranges\n",
    "def load_and_split_data(dataset_choice):\n",
    "    \"\"\"\n",
    "    Loads the selected dataset (household or dormitory), prepares the feature set and target variable,\n",
    "    and splits the data into predefined training and test sets based on specific row indices.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset_choice (str): 'household' or 'dormitory' to specify which dataset to load\n",
    "    \n",
    "    Returns:\n",
    "    - X_train, X_test, y_train, y_test: Split feature sets and target variables for training and testing\n",
    "    \"\"\"\n",
    "    if dataset_choice == 'household':\n",
    "        # Load household dataset\n",
    "        data = pd.read_csv('Appliances Energy Prediction.csv')\n",
    "        \n",
    "        # Define features and target variable based on specified row ranges\n",
    "        X_train = data.iloc[:2311, 1:-1]  # Training feature set\n",
    "        y_train = data.iloc[:2311, -1]    # Training target set\n",
    "        X_test = data.iloc[2311:, 1:-1]   # Test feature set\n",
    "        y_test = data.iloc[2311:, -1]     # Test target set\n",
    "        \n",
    "    elif dataset_choice == 'dormitory':\n",
    "        # Load dormitory dataset\n",
    "        data = pd.read_csv('University Residential Complex.csv')\n",
    "        \n",
    "        # Define features and target variable based on specified row ranges\n",
    "        X_train = data.iloc[:20472, 5:-1]  # Training feature set\n",
    "        y_train = data.iloc[:20472, -1]    # Training target set\n",
    "        X_test = data.iloc[20472:, 5:-1]   # Test feature set\n",
    "        y_test = data.iloc[20472:, -1]     # Test target set\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset choice. Please select 'household' or 'dormitory'.\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9841df6",
   "metadata": {},
   "source": [
    "## Step 3: Select Dataset and Split Data\n",
    "\n",
    "Here, we specify the dataset choice by setting the `dataset_choice` variable to either `'household'` or `'dormitory'`.<br>The `load_and_split_data` function is called, and the data is split into the training and test sets.<br>The shapes of these sets are displayed for verification.\n",
    "\n",
    "- **Example Usage**:\n",
    "  - Set `dataset_choice = 'household'` to load the household dataset.\n",
    "  - Set `dataset_choice = 'dormitory'` to load the dormitory dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2110d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# To select the dataset, pass either 'household' or 'dormitory' to the function\n",
    "dataset_choice = 'household'  # Change to 'dormitory' as needed\n",
    "X_train, X_test, y_train, y_test = load_and_split_data(dataset_choice)\n",
    "\n",
    "# Display the shapes of the train and test sets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad482caa",
   "metadata": {},
   "source": [
    "## Step 4: Define Feature Groups for Model Development\n",
    "\n",
    "After selecting and splitting the dataset, the next step is to organize the input variables into three distinct feature groups as specified in the paper:\n",
    "\n",
    "- **External Features**: Contains environmental and temporal variables.\n",
    "- **Internal Features**: Represents historical consumption-related data.\n",
    "- **Total Features**: A combination of both external and internal features.\n",
    "\n",
    "This setup allows us to test model performance with different types of input data, providing flexibility for feature engineering and model comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e17bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature groups based on input variable types\n",
    "external_features = [\"Hour_x\", \"Hour_y\", \"DOTW_x\", \"DOTW_y\", \"Holi\", \"Temp\", \"Humi\", \"WS\", \"THI\", \"WCT\"]\n",
    "internal_features = [\"Cons_1\", \"Holi_1\", \"Cons_7\", \"Holi_7\", \"Cons_avg\"]\n",
    "total_features = external_features + internal_features  # Combining both external and internal features\n",
    "target_variable = \"Consumption\"  # Dependent variable\n",
    "\n",
    "# Display the feature groups for verification\n",
    "print(\"External Features:\", external_features)\n",
    "print(\"Internal Features:\", internal_features)\n",
    "print(\"Total Features:\", total_features)\n",
    "print(\"Target Variable:\", target_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91ace19",
   "metadata": {},
   "source": [
    "## Summary of Feature Grouping\n",
    "\n",
    "The feature groups have been defined as follows:\n",
    "- **External Features**: Includes environmental factors and time-specific variables.\n",
    "- **Internal Features**: Contains historical consumption patterns and indicators.\n",
    "- **Total Features**: An aggregate of external and internal features for comprehensive analysis.\n",
    "\n",
    "These feature groups are now set up, and we are ready to proceed with model training and evaluation.<br>This approach will allow us to explore the individual contributions of each feature group to prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba81ba3",
   "metadata": {},
   "source": [
    "# Model Setup and Evaluation Functions\n",
    "\n",
    "We initialize five ensemble learning models (i.e., RF, GBM, XGBoost, LightGBM, and CatBoost) and perform hyperparameter tuning using GridSearchCV.<br>For each feature group (i.e., External, Internal, Total), we find the optimal hyperparameters for each model.<br>This step ensures that each model is optimized for the specific feature set.\n",
    "\n",
    "The models will be trained on each feature group, and the optimal hyperparameters will be saved for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333a590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grids for each model\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [128],\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "gbm_param_grid = {\n",
    "    'n_estimators': [100, 250, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [5, 10],\n",
    "    'loss': ['quantile', 'huber']\n",
    "}\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [250, 500, 1000],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [6, 8, 10],\n",
    "    'subsample': [0.5, 0.75, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.75, 1.0],\n",
    "    'booster': ['gbtree', 'dart']\n",
    "}\n",
    "lgbm_param_grid = {\n",
    "    'n_estimators': [1000, 1500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'num_leaves': [64],\n",
    "    'subsample': [0.5],\n",
    "    'colsample_bytree': [1.0],\n",
    "    'boosting_type': ['gbdt', 'dart']\n",
    "}\n",
    "catb_param_grid = {\n",
    "    'learning_rate': [0.03, 0.1],\n",
    "    'depth': [4, 6, 10],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69273517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate evaluation metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
    "    cvrmse = (np.sqrt(mean_squared_error(y_true, y_pred)) / np.mean(y_true)) * 100\n",
    "    nmae = (mean_absolute_error(y_true, y_pred) / np.mean(y_true)) * 100\n",
    "    \n",
    "    # Calculate Harmonic Mean\n",
    "    hm = 3 / ((1 / mape) + (1 / cvrmse) + (1 / nmae))\n",
    "    \n",
    "    return mape, cvrmse, nmae, hm\n",
    "\n",
    "# Define function for evaluation by Holi (Weekday, Holiday, All Days)\n",
    "def evaluate_model(model, X_test, y_test, feature_group):\n",
    "    results = {}\n",
    "    for holi_value, label in [(0, \"Weekday\"), (1, \"Holiday\"), (None, \"All Days\")]:\n",
    "        if holi_value is not None:\n",
    "            X_subset = X_test[X_test[\"Holi\"] == holi_value]\n",
    "            y_subset = y_test[X_test[\"Holi\"] == holi_value]\n",
    "        else:\n",
    "            X_subset = X_test\n",
    "            y_subset = y_test\n",
    "\n",
    "        predictions = model.predict(X_subset[feature_group])\n",
    "        mape, cvrmse, nmae, hm = calculate_metrics(y_subset, predictions)\n",
    "        \n",
    "        results[label] = {\n",
    "            \"MAPE\": mape,\n",
    "            \"CVRMSE\": cvrmse,\n",
    "            \"NMAE\": nmae,\n",
    "            \"HM\": hm\n",
    "        }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4044561",
   "metadata": {},
   "source": [
    "## Random Forest Regressor - Hyperparameter Tuning and Evaluation\n",
    "\n",
    "This cell initializes the Random Forest Regressor and performs hyperparameter tuning.<br>It then evaluates the model's performance on the **External**, **Internal**, and **Total** feature groups.<br>For each feature group, the model is evaluated based on the **Holi** variable (i.e., Weekday, Holiday, All Days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7eef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Function to train and evaluate Random Forest for each feature group\n",
    "def train_and_evaluate_rf(X_train, y_train, X_test, y_test, feature_group):\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    rf_grid = GridSearchCV(estimator=rf, param_grid=rf_param_grid, cv=5, scoring='neg_mean_absolute_percentage_error', n_jobs=-1)\n",
    "    rf_grid.fit(X_train[feature_group], y_train)\n",
    "    \n",
    "    # Save the best hyperparameters for the current feature group\n",
    "    rf_best_params = rf_grid.best_params_\n",
    "    print(f\"Random Forest best params for {feature_group}: {rf_best_params}\")\n",
    "    \n",
    "    # Evaluate model and return both metrics and best params\n",
    "    metrics = evaluate_model(rf_grid.best_estimator_, X_test, y_test, feature_group)\n",
    "    return metrics, rf_best_params\n",
    "\n",
    "# Initialize dictionaries to store results\n",
    "rf_results = {}\n",
    "rf_best_params = {}\n",
    "\n",
    "# Evaluate Random Forest on External, Internal, and Total feature groups\n",
    "for feature_group_name, features in zip([\"External\", \"Internal\", \"Total\"], [external_features, internal_features, total_features]):\n",
    "    metrics, best_params = train_and_evaluate_rf(X_train, y_train, X_test, y_test, features)\n",
    "    rf_results[feature_group_name] = metrics\n",
    "    rf_best_params[feature_group_name] = best_params\n",
    "\n",
    "# Display results for Random Forest\n",
    "for feature_group, metrics in rf_results.items():\n",
    "    print(f\"\\nFeature Group: {feature_group} - Random Forest\")\n",
    "    for segment, metric_values in metrics.items():\n",
    "        print(f\"  {segment}:\")\n",
    "        for metric_name, value in metric_values.items():\n",
    "            print(f\"    {metric_name}: {value:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8911b1f4",
   "metadata": {},
   "source": [
    "## Gradient Boosting Machine - Hyperparameter Tuning and Evaluation\n",
    "\n",
    "This cell initializes the Gradient Boosting Regressor, performs hyperparameter tuning.<br>It then evaluates the model's performance on the **External**, **Internal**, and **Total** feature groups.<br>For each feature group, the model is evaluated based on the **Holi** variable (i.e., Weekday, Holiday, All Days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9abbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Function to train and evaluate Gradient Boosting for each feature group\n",
    "def train_and_evaluate_gbm(X_train, y_train, X_test, y_test, feature_group):\n",
    "    gbm = GradientBoostingRegressor(random_state=42)\n",
    "    gbm_grid = GridSearchCV(estimator=gbm, param_grid=gbm_param_grid, cv=5, scoring='neg_mean_absolute_percentage_error', n_jobs=-1)\n",
    "    gbm_grid.fit(X_train[feature_group], y_train)\n",
    "    \n",
    "    # Save the best hyperparameters for the current feature group\n",
    "    gbm_best_params = gbm_grid.best_params_\n",
    "    print(f\"Gradient Boosting best params for {feature_group}: {gbm_best_params}\")\n",
    "    \n",
    "    # Evaluate model and return metrics\n",
    "    metrics = evaluate_model(gbm_grid.best_estimator_, X_test, y_test, feature_group)\n",
    "    return metrics, gbm_best_params\n",
    "\n",
    "# Evaluate Gradient Boosting on External, Internal, and Total feature groups\n",
    "gbm_results = {}\n",
    "gbm_best_params = {}\n",
    "\n",
    "for feature_group_name, features in zip([\"External\", \"Internal\", \"Total\"], [external_features, internal_features, total_features]):\n",
    "    metrics, best_params = train_and_evaluate_gbm(X_train, y_train, X_test, y_test, features)\n",
    "    gbm_results[feature_group_name] = metrics\n",
    "    gbm_best_params[feature_group_name] = best_params\n",
    "\n",
    "# Display results for Gradient Boosting\n",
    "for feature_group, metrics in gbm_results.items():\n",
    "    print(f\"\\nFeature Group: {feature_group} - Gradient Boosting\")\n",
    "    for segment, metric_values in metrics.items():\n",
    "        print(f\"  {segment}:\")\n",
    "        for metric_name, value in metric_values.items():\n",
    "            print(f\"    {metric_name}: {value:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a520656",
   "metadata": {},
   "source": [
    "## XGBoost Regressor - Hyperparameter Tuning and Evaluation\n",
    "\n",
    "This cell initializes the XGBoost Regressor, performs hyperparameter tuning.<br>It then evaluates the model's performance on the **External**, **Internal**, and **Total** feature groups.<br>Each feature group is evaluated based on the **Holi** variable (i.e., Weekday, Holiday, All Days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bc5afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Function to train and evaluate XGBoost for each feature group\n",
    "def train_and_evaluate_xgb(X_train, y_train, X_test, y_test, feature_group):\n",
    "    xgb = XGBRegressor(random_state=42, objective='reg:squarederror')\n",
    "    xgb_grid = GridSearchCV(estimator=xgb, param_grid=xgb_param_grid, cv=5, scoring='neg_mean_absolute_percentage_error', n_jobs=-1)\n",
    "    xgb_grid.fit(X_train[feature_group], y_train)\n",
    "    \n",
    "    # Save the best hyperparameters for the current feature group\n",
    "    xgb_best_params = xgb_grid.best_params_\n",
    "    print(f\"XGBoost best params for {feature_group}: {xgb_best_params}\")\n",
    "    \n",
    "    # Evaluate model and return metrics\n",
    "    metrics = evaluate_model(xgb_grid.best_estimator_, X_test, y_test, feature_group)\n",
    "    return metrics, xgb_best_params\n",
    "\n",
    "# Evaluate XGBoost on External, Internal, and Total feature groups\n",
    "xgb_results = {}\n",
    "xgb_best_params = {}\n",
    "\n",
    "for feature_group_name, features in zip([\"External\", \"Internal\", \"Total\"], [external_features, internal_features, total_features]):\n",
    "    metrics, best_params = train_and_evaluate_xgb(X_train, y_train, X_test, y_test, features)\n",
    "    xgb_results[feature_group_name] = metrics\n",
    "    xgb_best_params[feature_group_name] = best_params\n",
    "\n",
    "# Display results for XGBoost\n",
    "for feature_group, metrics in xgb_results.items():\n",
    "    print(f\"\\nFeature Group: {feature_group} - XGBoost\")\n",
    "    for segment, metric_values in metrics.items():\n",
    "        print(f\"  {segment}:\")\n",
    "        for metric_name, value in metric_values.items():\n",
    "            print(f\"    {metric_name}: {value:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e0467c",
   "metadata": {},
   "source": [
    "## LightGBM Regressor - Hyperparameter Tuning and Evaluation\n",
    "\n",
    "This cell initializes the LightGBM Regressor, performs hyperparameter tuning.<br>It then evaluates the model's performance on the **External**, **Internal**, and **Total** feature groups.<br>For each feature group, the model is evaluated based on the **Holi** variable (i.e., Weekday, Holiday, All Days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5390dd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Function to train and evaluate LightGBM for each feature group\n",
    "def train_and_evaluate_lgbm(X_train, y_train, X_test, y_test, feature_group):\n",
    "    lgbm = LGBMRegressor(random_state=42)\n",
    "    lgbm_grid = GridSearchCV(estimator=lgbm, param_grid=lgbm_param_grid, cv=5, scoring='neg_mean_absolute_percentage_error', n_jobs=-1)\n",
    "    lgbm_grid.fit(X_train[feature_group], y_train)\n",
    "    \n",
    "    # Save the best hyperparameters for the current feature group\n",
    "    lgbm_best_params = lgbm_grid.best_params_\n",
    "    print(f\"LightGBM best params for {feature_group}: {lgbm_best_params}\")\n",
    "    \n",
    "    # Evaluate model and return metrics\n",
    "    metrics = evaluate_model(lgbm_grid.best_estimator_, X_test, y_test, feature_group)\n",
    "    return metrics, lgbm_best_params\n",
    "\n",
    "# Evaluate LightGBM on External, Internal, and Total feature groups\n",
    "lgbm_results = {}\n",
    "lgbm_best_params = {}\n",
    "\n",
    "for feature_group_name, features in zip([\"External\", \"Internal\", \"Total\"], [external_features, internal_features, total_features]):\n",
    "    metrics, best_params = train_and_evaluate_lgbm(X_train, y_train, X_test, y_test, features)\n",
    "    lgbm_results[feature_group_name] = metrics\n",
    "    lgbm_best_params[feature_group_name] = best_params\n",
    "\n",
    "# Display results for LightGBM\n",
    "for feature_group, metrics in lgbm_results.items():\n",
    "    print(f\"\\nFeature Group: {feature_group} - LightGBM\")\n",
    "    for segment, metric_values in metrics.items():\n",
    "        print(f\"  {segment}:\")\n",
    "        for metric_name, value in metric_values.items():\n",
    "            print(f\"    {metric_name}: {value:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c386712c",
   "metadata": {},
   "source": [
    "## CatBoost Regressor - Hyperparameter Tuning and Evaluation\n",
    "\n",
    "This cell initializes the CatBoost Regressor, performs hyperparameter tuning.<br>It then evaluates the model's performance on the **External**, **Internal**, and **Total** feature groups.<br>For each feature group, the model is evaluated based on the **Holi** variable (i.e., Weekday, Holiday, All Days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2608d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Function to train and evaluate CatBoost for each feature group\n",
    "def train_and_evaluate_catb(X_train, y_train, X_test, y_test, feature_group):\n",
    "    catb = CatBoostRegressor(random_state=42, verbose=0)\n",
    "    catb_grid = GridSearchCV(estimator=catb, param_grid=catb_param_grid, cv=5, scoring='neg_mean_absolute_percentage_error', n_jobs=-1)\n",
    "    catb_grid.fit(X_train[feature_group], y_train)\n",
    "    \n",
    "    # Save the best hyperparameters for the current feature group\n",
    "    catb_best_params = catb_grid.best_params_\n",
    "    print(f\"CatBoost best params for {feature_group}: {catb_best_params}\")\n",
    "    \n",
    "    # Evaluate model and return metrics\n",
    "    metrics = evaluate_model(catb_grid.best_estimator_, X_test, y_test, feature_group)\n",
    "    return metrics, catb_best_params\n",
    "\n",
    "# Evaluate CatBoost on External, Internal, and Total feature groups\n",
    "catb_results = {}\n",
    "catb_best_params = {}\n",
    "\n",
    "for feature_group_name, features in zip([\"External\", \"Internal\", \"Total\"], [external_features, internal_features, total_features]):\n",
    "    metrics, best_params = train_and_evaluate_catb(X_train, y_train, X_test, y_test, features)\n",
    "    catb_results[feature_group_name] = metrics\n",
    "    catb_best_params[feature_group_name] = best_params\n",
    "\n",
    "# Display results for CatBoost\n",
    "for feature_group, metrics in catb_results.items():\n",
    "    print(f\"\\nFeature Group: {feature_group} - CatBoost\")\n",
    "    for segment, metric_values in metrics.items():\n",
    "        print(f\"  {segment}:\")\n",
    "        for metric_name, value in metric_values.items():\n",
    "            print(f\"    {metric_name}: {value:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14e1068",
   "metadata": {},
   "source": [
    "## Save Results to .txt and .csv Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0f07b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Combine best hyperparameters for each model\n",
    "all_best_params = {\n",
    "    \"Random Forest\": rf_best_params,\n",
    "    \"Gradient Boosting\": gbm_best_params,\n",
    "    \"XGBoost\": xgb_best_params,\n",
    "    \"LightGBM\": lgbm_best_params,\n",
    "    \"CatBoost\": catb_best_params\n",
    "}\n",
    "\n",
    "# Combine all results and best parameters\n",
    "all_results = {\n",
    "    \"Random Forest\": rf_results,\n",
    "    \"Gradient Boosting\": gbm_results,\n",
    "    \"XGBoost\": xgb_results,\n",
    "    \"LightGBM\": lgbm_results,\n",
    "    \"CatBoost\": catb_results\n",
    "}\n",
    "\n",
    "# Save best hyperparameters to a .txt file\n",
    "with open(\"optimal_hyperparameters.txt\", \"w\") as f:\n",
    "    for model_name, best_params in all_best_params.items():\n",
    "        f.write(f\"Model: {model_name}\\n\")\n",
    "        for param, value in best_params.items():\n",
    "            f.write(f\"  {param}: {value}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# Save evaluation metrics to a .csv file\n",
    "with open(\"evaluation_metrics.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    fieldnames = [\"Model\", \"Feature Group\", \"Segment\", \"MAPE\", \"CVRMSE\", \"NMAE\", \"HM\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for model_name, feature_results in all_results.items():\n",
    "        for feature_group, results in feature_results.items():\n",
    "            for segment, metrics in results.items():\n",
    "                row = {\"Model\": model_name, \"Feature Group\": feature_group, \"Segment\": segment}\n",
    "                row.update(metrics)\n",
    "                writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
